{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f146bc70",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import numpy as np\n",
    "import random\n",
    "import statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0dc57dcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import namedtuple, deque\n",
    "from itertools import count\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cc5547c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import torchvision.transforms as T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "11fbe2a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Rewarder(nn.Module):\n",
    "    def __init__(self, num_hidden_units, input_dim):\n",
    "        super(Rewarder,self).__init__()\n",
    "        \n",
    "        self.rewarder_net = nn.Sequential(\n",
    "            nn.Linear(input_dim, num_hidden_units),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(num_hidden_units,1)\n",
    "        ) \n",
    "        \n",
    "    def forward(self, input_obs):\n",
    "        return int(self.rewarder_net(input_obs))\n",
    "    \n",
    "\n",
    "class Actor(nn.Module):\n",
    "    def __init__(self, num_actions, num_hidden_units, input_dim):\n",
    "        super(Actor,self).__init__()\n",
    "        \n",
    "        self.actor_net = nn.Sequential(\n",
    "            nn.Linear(input_dim, num_hidden_units),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(num_hidden_units,num_actions),\n",
    "            nn.Softmax(dim=0)\n",
    "        ) \n",
    "        \n",
    "        \n",
    "    def forward(self, input_obs):\n",
    "        return self.actor_net(input_obs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "c8f935f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GridWorld():\n",
    "    def __init__(self):\n",
    "        self.state = self.init_state()\n",
    "        self.step_count = 0\n",
    "        \n",
    "    def init_state(self):\n",
    "        xs = random.sample(range(0,7),5)\n",
    "        ys = random.sample(range(0,7),5)\n",
    "        piece_pos = [xs[0], ys[0]]\n",
    "        players_pos = [xs[4], ys[4]]\n",
    "        positions = list(np.array([players_pos, piece_pos]).flatten())\n",
    "        return positions\n",
    "        \n",
    "    def reset(self):\n",
    "        self.state = self.init_state()\n",
    "        self.step_count = 0\n",
    "        \n",
    "    def step(self, action):\n",
    "        self.step_count += 1\n",
    "        \n",
    "        if action == 0: #up\n",
    "            self.state[1] += 1\n",
    "            \n",
    "        if action == 1: #right\n",
    "            self.state[0] += 1\n",
    "            \n",
    "        if action == 2: #down\n",
    "            self.state[1] -= 1\n",
    "            \n",
    "        if action == 3: #left\n",
    "            self.state[0] -= 1\n",
    "            \n",
    "        if (self.step_count >= 25) : # loss max step\n",
    "            self.reset()\n",
    "            # reward function\n",
    "            # with torch.no_grad():\n",
    "            #    reward = int(rewarder(torch.unsqueeze(self.state, 0), training=False)[0])\n",
    "            reward = int(rewarder(self.state))\n",
    "            playing = False\n",
    "            \n",
    "            return reward, playing\n",
    "        \n",
    "        if (self.state[0] == self.state[2]) and (self.state[1] == self.state[3]): # win the game\n",
    "            playing = False\n",
    "            reward = 100\n",
    "            # reward learning model\n",
    "            # with torch.no_grad():\n",
    "            #    reward = int(rewarder(torch.unsqueeze(self.state, 0), training=False)[0])\n",
    "            self.reset()\n",
    "            return reward, playing\n",
    "        \n",
    "        playing = True\n",
    "\n",
    "        # reward function\n",
    "        #with torch.no_grad():\n",
    "        #    reward = int(rewarder(torch.unsqueeze(self.state, 0), training=False)[0])\n",
    "        reward = int(rewarder(torch.Tensor(self.state)))\n",
    "        \n",
    "        return reward, playing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "8d2d32e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[6, 2, 4, 1]"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rewarder = Rewarder(num_hidden_units = 64, input_dim = 4)\n",
    "agent = Actor(num_actions = 4, num_hidden_units = 64, input_dim = 4)\n",
    "env = GridWorld()\n",
    "env.state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "6eb39a4a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "action_proba = agent(torch.Tensor(env.state))\n",
    "action_index = torch.argmax(action_proba)\n",
    "reward, playing = env.step(action_index)\n",
    "reward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "b10ee609",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[6, 1, 4, 1]"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "43e97f8c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x2462427a5e0>"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots(1,2)\n",
    "colors = ['yellow','green']\n",
    "\n",
    "color_indices = [0, 1]\n",
    "colormap = matplotlib.colors.ListedColormap(colors)\n",
    "\n",
    "ax[0].scatter([env.state[0], env.state[2]] , [env.state[1],env.state[3]], c=color_indices, cmap=colormap)\n",
    "\n",
    "ax[1].scatter([env.state[0], env.state[2]] , [env.state[1],env.state[3]], c=color_indices, cmap=colormap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "5134ec7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare (transition_ids, states, actions):\n",
    "    states = 0\n",
    "    d1xs = [states[transition_ids[0]][0][0], states[transition_ids[0]][0][2]]\n",
    "    d1ys = [states[transition_ids[0]][0][1], states[transition_ids[0]][0][3]]\n",
    "    d2xs = [states[transition_ids[1]][0][0], states[transition_ids[0]][0][2]]\n",
    "    d2ys = [states[transition_ids[1]][0][1], states[transition_ids[0]][0][3]]\n",
    "\n",
    "    fig, ax = plt.subplots(2,2)\n",
    "    colors = ['yellow','green']\n",
    "    color_indices = [0, 1, ]\n",
    "    colormap = matplotlib.colors.ListedColormap(colors)\n",
    "    ax[0,0].scatter(d1xs, d1ys, c=color_indices, cmap=colormap)\n",
    "    ax[0,0].set_title(str(decode_action(actions[transition_ids[0]].numpy())))\n",
    "    ax[0,1].scatter(d2xs, d2ys, c=color_indices, cmap=colormap)\n",
    "    ax[0,1].set_title(str(decode_action(actions[transition_ids[1]].numpy())))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "f01b53e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode_action(action):\n",
    "    if action == 0:\n",
    "        return 'up'\n",
    "    if action == 1:\n",
    "        return 'right'\n",
    "    if action == 2:\n",
    "        return 'down'\n",
    "    if action == 3:\n",
    "        return 'left'        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27f3ef7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# here states ref to a lot of differents states\n",
    "def preference_update( states, actions, rewarder):\n",
    "    transition_ids = random.sample(range(0, len(states) -2), 2)\n",
    "    compare(transition_ids, states, actions)\n",
    "    pref = input (' select preference a:left, d:right, s:same ')\n",
    "    if pref == 'a':\n",
    "        dist = [ 1, 0 ]\n",
    "    if pref == 'd':\n",
    "        dist = [ 0, 1 ]\n",
    "    if pref == 's':\n",
    "        dist = [ 1, 1 ]\n",
    "        \n",
    "    # stuff gradient\n",
    "    reward_1 = rewarder( state[transition_ids[0] + 1])\n",
    "    reward_2 = rewarder( state[transition_ids[1] + 1])\n",
    "    p1 = torch.exp(reward_1) / (torch.exp(reward_1) + torch.exp(reward_2))\n",
    "    p2 = torch.exp(reward_2) / (torch.exp(reward_1) + torch.exp(reward_2))\n",
    "    loss = - ( p1*dist[0] + p2*dist[1] )\n",
    "    #grads = torch gradient (loss, rewarder variable)\n",
    "    # optimizer ( grads, rewarder)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a53bbaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train the reward funtion on a state and action\n",
    "# return multiple states\n",
    "def step_episode(env, model):\n",
    "    env.reset()\n",
    "    action_prob_list = []\n",
    "    rewards = []\n",
    "    states = []\n",
    "    actions = []\n",
    "    playing = True\n",
    "    \n",
    "    while playing == True\n",
    "        observation = expand dim (env.state)\n",
    "        \n",
    "        # run model\n",
    "        action_logits = agent(obs)\n",
    "        \n",
    "        #categorical probabilistic action idx selection\n",
    "        selected_action_idx = random categorical (action_logits, 1 )[ 0, 0]\n",
    "        \n",
    "        states.append(observation)\n",
    "        action.append(selected_action_idx)\n",
    "        \n",
    "        reward, playing = env.step(selected_action_idx)\n",
    "        \n",
    "        #normalize proba\n",
    "        action_probs = softmax function ( action_logits)\n",
    "        probability_of_taking_selected_action = action_probs[0, selected_action_idx]\n",
    "        action_probs_list.append(probability_of_taking_selected_action)\n",
    "        rewards.append(reward)\n",
    "        \n",
    "    return action_probs_list, rewards, states, actions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00239b66",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent = Actor (num_action = 4, num_hidden_units = 100)\n",
    "\n",
    "rewarder = Rewarder(num_hidden_unites = 100)\n",
    "\n",
    "env = GridWorld()\n",
    "optimizer = torch.optim.Adam(policy_net.parameters(), lr=1e-4)\n",
    "\n",
    "# criterion = nn.CrossEntropyLoss()\n",
    "# loss = self.criterion(output, train_target.narrow(0, b, mini_batch_size))\n",
    "#                acc_loss = acc_loss + loss.item()\n",
    "#                self.autoenc.zero_grad()\n",
    "#                loss.backward()\n",
    "#                self.optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77c9e1a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_g(reward_trajectory, gamma):\n",
    "    ez_discount = np.array([ gamma**n for n in range(len(reward_trajectory))])\n",
    "    gs = []\n",
    "    reward_trajectory = np.array(reward_trajectory)\n",
    "    for ts in range(len(reward_trajectory)):\n",
    "        to_end_rewards = reward_trajectory[ts:]\n",
    "        eq_len_discount = ez_discount[:len(reward_trajectory[ts:])]\n",
    "        total_value = np.multiply(to_end_rewards, eq_len_discount)\n",
    "        g = sum(total_value)\n",
    "        gs.append(g)\n",
    "    return gs   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad4d979b",
   "metadata": {},
   "outputs": [],
   "source": [
    "for episode in range(5000):\n",
    "    action_probs, rewards, states ,actions = step_episode (env, agent)\n",
    "    loss = actor_loss (action_probs ,rewards)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
